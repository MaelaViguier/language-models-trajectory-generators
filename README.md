# Language Models as Zero-Shot Trajectory Generators

## Teyun Kwon, Norman Di Palo, Edward Johns

[The Robot Learning Lab](https://www.robot-learning.uk/), Department of Computing, Imperial College London

[[arXiv](https://arxiv.org/abs/2310.11604)] [[project page](https://www.robot-learning.uk/language-models-trajectory-generators)]

In this work, we investigate if an LLM (GPT-4) can directly predict a dense sequence of end-effector poses for manipulation skills, when given access to only object detection and segmentation vision models, and without any in-context examples, motion primitives, or external trajectory optimisers, with only a single task-agnostic prompt.

This repository currently contains the full prompts, and the prompts used for ablation studies, along with an example LLM output.

Code will be uploaded in the coming days. Stay tuned!
